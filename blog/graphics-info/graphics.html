<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="../../styles.css"> </link>
        <link rel="stylesheet" href="../blog.css"> </link>
        <title> Graphics </title>
        <meta name = "viewport" content = "width=1000"> </meta>
        <meta charset = "UTF-8"> </meta>
    </head>
    
    <body>
        <div class = "header" id = "header">
            <div class = "headerSection">
                <p> <a href = "../index.html" style = "text-decoration: none; color: white;"> Blog Home </a> </p>
            </div>
            <div class = "headerSection">
                <p> <a href = "../../index.html" style = "text-decoration: none; color: white;"> Home </a> </p>
            </div>
        </div>
        <p style = "text-align: center; font-size: 25px;"> ðŸ‘· <b>Work in Progress</b> ðŸ‘· </p>
        <div class = "content" style = "visibility: ;">


            <h1> Junior Graphics Engineer Interview Questions </h1>
            <p>
                Junior graphics engineer interviews require a lot more domain-specific knowledge than your typical junior software engineer interviews. I've failed many interviews because I didn't fully understand common graphics interview topics. So I made this page to include some common interview topics I encountered during my interview process. I'm not going to go super in depth on all topics on this page, but I will link to other resources that do go in depth. Not all these topics will come up, but it's good to have familiarity with all of the topics.
            </p>


            <h2 class = "sectionHeader"> Math </h2>
            
            <p class = "subsectionHeader"> <b> Powers of 2 </b> </p>
            <div class = "subsectionContent">
                <p> 
                    Yes, really. I've been directly asked about them in at least 2<sup>1</sup> interviews.
                </p>
                <p>
                    I just know that 2<sup>4</sup> = 16, 2<sup>8</sup> = 256, and that I can multiply or divide by 2 to get whatever specific power of 2 I get asked to compute.
                </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Power_of_two#Table_of_values" target = "_blank"> Powers of 2 (Wikipedia) </a>
                </div>
            </div>


            <p class = "subsectionHeader"> <b> Hexadecimal </b> </p>
            <div class = "subsectionContent"> 
                <p> Like binary, but with 16 numbers. </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Hexadecimal" target = "_blank"> Hexadecimal (Wikipedia) </a>
                </div>
            </div>



            <p class = "subsectionHeader"> <b> Two's compliment </b> </p>
            <div class = "subsectionContent">
                <p> To create a negative number in two's compliment, determine the binary representation of the positive number, flip the bits, and add 1. </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Two%27s_complement#From_the_ones'_complement" target = "_blank"> Two's compliment (Wikipedia) </a>
                </div>
            </div>


            <p class = "subsectionHeader"> <b> Matrices </b> </p>
            <div class = "subsectionContent">
                <p class = "noBottom"> Rotation matrix properties </p>
                <ul>
                    <li> Each column vector is normalized </li> 
                    <li> Dot product of 2 unique column vectors is 0 </li> 
                    <li> All column vectors are orthonormal to each other, form an orthonormal basis </li> 
                    <li> Inverse matrix is the transpose </li> 
                </ul>
                <p> Model matrix is model -> world space </p>
                <p> View matrix is world -> camera space </p>
                <p> Projection matrix applies perspective correction to the view frustum </p>
                <p> Multiplication order matters, typically we multiply by scale, then rotation, then translation. </p>
                <div class = "links">
                    
                    <a href = "https://en.wikipedia.org/wiki/Rotation_matrix" target = "_blank"> Rotation matrix (Wikipedia) </a>
                    <br/>
                    <a href = "http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/" target = "_blank"> Tutorial 3 : Matrices (OpenGL-tutorial) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Ray intersections </b> </p>
            <div class = "subsectionContent">
                <p> A ray is defined at <b>x = dt + o</b>, where x is position, d is direction, t is time/distance, o is origin. d and o are normalized. </p>

                <p class = "noBottom"> Sphere </p>
                <ul> 
                    <li> r<sup>2</sup> = dot(x - p, x - p) </li>
                    <ul> 
                        <li>r is the radius of the sphere</li> 
                        <li> p is the center</li> 
                    </ul>
                    <li> r<sup>2</sup> = dot(dt + o - p, dt + o - p) </li>
                    <li> r<sup>2</sup> = dot(dt + R, dt + R) </li>
                    <ul> 
                        <li> R = o - p </li>
                    </ul>
                    <li> r<sup>2</sup> = d<sup>2</sup> * t<sup>2</sup> + 2dRt + R<sup>2</sup> </li>
                    <li> 0 = d<sup>2</sup> * t<sup>2</sup> + 2d(o - p)t + (o - p)<sup>2</sup> - r<sup>2</sup> </li>
                    <li> 0 = At<sup>2</sup> + Bt + C </li>
                    <ul> 
                        <li> A = dot(d, d) </li>
                        <li> B = 2 * dot(d, o - p) </li>
                        <li> C = dot(o - p, o - p) - r<sup>2</sup></li>
                    </ul>
                    <li> Use quadratic equation to solve for real solutions of t. </li>
                    <ul> 
                        <li> Two solutions: two intersection points on the sphere, usually take the closer point </li>
                        <li> One solution: ray is tangent to the sphere </li>
                        <li> Zero solutions: no intersection point </li>
                    </ul>
                </ul>

                <p class = "noBottom"> Plane </p>
                <ul>
                    <li> 0 = dot(x - p, n) </li>
                    <ul> 
                        <li> p is a point on the plane </li>
                        <li> n is the plane's normal </li>
                    </ul>
                    <li> 0 = dot(dt + o - p, n)</li>
                    <li> 0 = dot(d, n) * t + dot(o - p, n)</li>
                    <li> -dot(o - p, n) / dot(d, n) = t </li>
                    <ul> 
                        <li> t is negative: the ray is facing away from the plane </li>
                        <li> dot(d, n) = 0: ray and plane are parallel </li>
                    </ul>
                </ul>
                <div class = "links">
                    <a href = "https://www.scratchapixel.com/lessons/3d-basic-rendering/minimal-ray-tracer-rendering-simple-shapes/ray-sphere-intersection" target = "_blank"> Ray-Sphere Intersection (Scratchapixel) </a>
                    <br/>
                    <a href = "https://courses.cs.washington.edu/courses/csep557/10au/lectures/triangle_intersection.pdf" target = "_blank"> Ray-triangle intersection (Brian Curless) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Dot/Cross products </b> </p>
            <div class = "subsectionContent">
                <p class = "noBottom"> Dot product </p>
                <ul>
                    <li> The angle between two vectors </li>
                    <li> dot(a, b) = length(a) * length(b) * cos(theta) </li>
                    <li> For normalized vectors, the range of dot product is -1 to 1 </li>
                    <ul>
                        <li> dot = 1: parallel facing same way (0 degrees) </li>
                        <li> dot = 0: normal/orthogonal (90 degrees) </li>
                        <li> dot = -1: parallel, facing opposite (180 degrees) </li>
                        <li> <b>The dot product between two parallel vectors is -1 or 1.</b> (Most people just say 1 apparently) </li>
                    </ul>
                    <li> Dot product is used in the rendering equation, BRDFs, phong shading, determining angle between two vectors. </li>
                </ul>
                <p class = "noBottom"> Cross product </p>
                <ul> 
                    <li> AxB = vector that is orthogonal to A and B. </li>
                    <li> AxB = -(BxA) = (-A)xB </li>
                    <li> A.(AxB) = B.(AxB) = 0 </li>
                    <li> length(AxB) = area of the parallelogram created by A and B </li>
                    <li> Cross product is used to generate a camera basis, or to create a normal vector for a plane from 3 points. </li>
                </ul>
            </div>

            <p class = "subsectionHeader"> <b> Quaternions </b> </p>
            <div class = "subsectionContent">
                <p> Way to represent rotation with 4D numbers. </p>
                <div class = "links">
                    <a href = "https://wrf.ecse.rpi.edu/pmwiki/pmwiki.php/Research/Quaternions" target = "_blank"> Quaternions (W. Randolph Franklin) </a>
                    <!-- https://wrf.ecse.rpi.edu/pmwiki/Research/Quaternions -->
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Euler Angles </b> </p>
            <div class = "subsectionContent">
                <p> Simple way to represent rotation. Can run into Gimbal lock, better to use quaternions. </p>
                <div class = "links">
                    <a href = "https://mathworld.wolfram.com/EulerAngles.html" target = "_blank"> Euler Angles (Wolfram) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Gimbal_lock" target = "_blank"> Gimbal lock (Wikipedia) </a>
                </div>
            </div>            

            <p class = "subsectionHeader"> <b> Barycentric Coordinates </b> </p>
            <div class = "subsectionContent">
                <p> Coordinate system where you represent a point on a triangle by the weighted sum of the triangle's vertices. </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Barycentric_coordinate_system" target = "_blank"> Barycentric Coordinates (Wikipedia) </a>
                </div>
            </div>            

            <p class = "subsectionHeader"> <b> Rendering Equation </b> </p>
            <div class = "subsectionContent">
                <img src = "https://wikimedia.org/api/rest_v1/media/math/render/svg/3955fb75fee8d1ace1e117f728dd33f919262b36" style = "width: 80%;"/>


                <p>
                    For each input direction wi, calculate the light absorbed (irradiance) by the surface along wi (Li * wi&#183;n), then multiply that value by the amount of the absorbed light that exits the surface (radiance) in the direction of wo (fr). Then, if the surface itself emits light, calculate the amount of radiance that leaves the surface along wo (Le) and add it to the previous sum. This is equal to the total amount of radiance that leaves the surface along wo (Lo).
                </p>

                <p> 
                    Why is irradiance = Li * wi&#183;n? Iradiance is flux per unit area. The radiance (Li) is the flux. To understand how the dot product give us 'per unit area', lets think about a flashlight. If you hold a flashlight directly above a table, a flashlight will form a circle on the table. As you tilt the flashlight so that it is at a 45 degree angle to the table, the circle will turn into an ellipse. The radiance in these two cases is the same, but the area covered by the light is more in the 45 degree case, so the irradiance is smaller. This effect is modeled with the dot product term. You can see this effect visually below.
                </p>

                <img src = "https://upload.wikimedia.org/wikipedia/commons/c/ca/Oswietlenie_lamberta.svg" style = "width: 400px;"/>


                <p> 
                    Rendering equation is impossible to solve exactly, so it has to be approximated. The basic rendering equation does not capture some rendering effects like subsurface scattering, transmission, and volumetric effects. However, the rendering equation can be modified to accomodate these effects by integrating over the whole sphere instead of the hemisphere.
                </p>


                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Rendering_equation" target = "_blank"> Rendering Equation (Wikipedia) </a>
                </div>
            </div> 




            <p class = "subsectionHeader"> <b> BXDF </b> </p>
            <div class = "subsectionContent">
                <p class = "noBottom"> Bidirectional X Distribution function, where X is </p>
                <ul class = "noTop"> 
                    <li> Reflectance </li>
                    <li> Transmission </li>
                    <li> Surface </li>
                    <li> Subsurface Scattering </li>
                </ul>

                <p> Takes in two inputs, light direction into a surface (wi), light direction out of the surface (wo). The output of a BXDF is the ratio of radiance to irradiance for the surface. The amount of light absorbed along wi that is reflected out along wo. The %chance that a ray coming in along wi will reflect out along wo. </p>

                <img src = "https://wikimedia.org/api/rest_v1/media/math/render/svg/49e75397f3740b44e763145f6c8c64578b2440e7" style = "width: 400px;"/>


                <p class = "noBottom"> Properties of BXDFs </p>
                <ul class = "noTop"> 
                    <li> All outputs are of the BXDF are non-negaive. </li>
                    <li> Helmholtz reciprocity, BXDF(wi, wo) = BXDF(wo, wi) </li>
                    <li> Conserves energy, integral of the BRDF is 1. </li>
                </ul>


                <p class = "noBottom"> Types of BRDFs </p>
                <ul class = "noTop"> 
                    <li> Lambertian </li>
                    <li> Disney Diffuse </li>
                    <li> Blinn-Phong </li>
                    <li> Cook-Torrance </li>
                </ul>

                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Bidirectional_reflectance_distribution_function" target = "_blank"> BRDF (Wikipedia) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Blinnâ€“Phong_reflection_model" target = "_blank"> Blinn-Phong (Wikipedia) </a>
                    <br/>
                    <a href = "http://www.codinglabs.net/article_physically_based_rendering_cook_torrance.aspx" target = "_blank"> Cook-Torrance (Wikipedia) </a>
                    <br/>
                    <a href = "https://sakibsaikia.github.io/graphics/2019/09/10/Deriving-Lambertian-BRDF-From-First-Principles.html" target = "_blank"> Lambertian (Sakib Saikia) </a>
                    <br/>
                    <a href = "https://media.disneyanimation.com/uploads/production/publication_asset/48/asset/s2012_pbs_disney_brdf_notes_v3.pdf" target = "_blank"> Disney Diffuse (Brent Burley) </a>
                </div>
            </div>


            <p class = "subsectionHeader"> <b> Sampling </b> </p>
            <div class = "subsectionContent">
                <p> In graphics, we have to approximate things, like the rendering equation. We use various sampling techniques to calculate the approximations. We are trying to avoid aliasing/jagged edges in the images we render, sampling helps to do that. </p>
                <div class = "links">
                    <a href = "http://web.cs.wpi.edu/~emmanuel/courses/cs563/S10/talks/wk3_p1_wadii_sampling_techniques.pdf" target = "_blank"> Sampling Techniques (Wadii Bellamine) </a>
                    <br/>
                    <a href = "https://www.cs.rpi.edu/~cutler/classes/advancedgraphics/F05/lectures/20_sampling_aliasing.pdf" target = "_blank"> Sampling, Aliasing, & Mipmaps (Barb Cutler) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Importance Sampling </b> </p>
            <div class = "subsectionContent">
                <p> The reason that importance sampling is so important is due to the following observation: whether a given sample contributes 50% or 0.1% to the final sum, the time it takes to evaluate the function at the two sample points is the same. Because of this, we should spend more time evaluating areas of the interval that contribute significantly to the final sum, and less time on areas that do not contribute much. </p>
                <div class = "links">
                    <a href = "http://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Importance_Sampling.html" target = "_blank"> Importance Sampling (Pharr, Jakob, Humphreys) </a>
                    <br/>
                    <a href = "../sampling/sampling.html" target = "_blank"> Intro to Sampling (made by me!) </a>
                </div>
            </div>


            <h2 class = "sectionHeader"> Graphics pipeline </h2>
            <p class = "subsectionHeader"> <b> Pipeline </b> </p>
            <div class = "subsectionContent">

                <ul> 
                    <li> Vertex shader </li>
                    <ul> 
                        <li> Runs per vertex/point in the mesh. Typically transform mesh vertices from model space to screen space. Vertex shaders predominently use the GPU's matrix vector multipliction. </li>
                    </ul>
                    <li> Optional Tessellation shader </li>
                    <ul> 
                        <li> Used to create subdivided/fine detailed geometry within an input triangle patch. </li>
                    </ul>
                    <li> Optional Geometry shader </li>
                    <ul> 
                        <li> Used to create new geometry, like shadow volumes. </li>
                    </ul>
                    <li> Clipping </li>
                    <ul> 
                        <li> Remove vertices that are outside of the 1x1x1 cube, add new vertices if neccesary. </li>
                    </ul>
                    <li> Primative Assembly </li>
                    <ul> 
                        <li> Turn vertices into shapes (triangles, points, lines) </li>
                    </ul>
                    <li> Face culling </li>
                    <ul> 
                        <li> Front face/back face culling. If triangles face away from the screen, they are likely behind triangles that face the camera, so we should ignore them. This means triangles have a winding order (CW or CCW). </li>
                    </ul>
                    <li> Rasterization </li>
                    <ul> 
                        <li> Takes the triangles and figures out which pixels are covered by the triangles. If doing MSAA, might take multiple samples per pixel to reduce jaggies. </li>
                    </ul>
                    <li> Optional Early depth test </li>
                    <ul> 
                        <li> Depth test fragment against previously written depth for the pixel. If current fragment will be behind what is currently there, ignore this fragment to save power. </li>
                    </ul>
                    <li> Fragment shader </li>
                    <ul> 
                        <li> Take interpolated vertex output data, use it as input to calculate the pixel's color. </li>
                    </ul>
                    <li> depth/stencil test/alpha blending </li>
                    <ul> 
                        <li> Write to render target if this fragment will be in front of what is currently there. Same for stencil testing, also need to do alpha blending. Typically, depth and stencil occur before fragment shading, but it's possible to change the depth of a fragment in a fragment shader which would force depth test afterwards. </li>
                    </ul>
                </ul>
                <div class = "links">
                    <a href = "https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview" target = "_blank"> Rendering Pipeline Overview (Khronos) </a>
                </div>
            </div>


            <p class = "subsectionHeader"> <b> TBDR </b> </p>
            <div class = "subsectionContent">
                <p> Tile Based Deferred Rendering. Vertices are binned into tiles, then each tile is rendered separately, which reduces memory bandwidth between pipeline stages. </p>
                <div class = "links">
                    <a href = "https://developer.apple.com/videos/play/wwdc2020/10602/" target = "_blank"> Harness Apple GPUs with Metal (Apple) </a>
                </div>
            </div>


            <h2 class = "sectionHeader"> CPU/GPU Architecture </h2>

            <p class = "subsectionHeader"> <b> Stack vs heap </b> </p>
            <div class = "subsectionContent">
                <p class = "noBottom"> Stack </p>
                <ul>
                    <li> A sequential block of memory, basically an array. </li>
                    <li> There is a stack pointer that points to the top of the stack. </li>
                    <li> Stack allocation is very quick, because adding new memory to the stack just requires incrementing the stack pointer. Deallocation is the same. </li>
                    <li> Meant for 'temporary variables' that are locally scoped within a function that won't be needed after the function returns. </li>
                    <li> Compiler can make some optimizations to preallocate all stack memory for a function when it is called </li>
                </ul>
                <p class = "noBottom"> Heap </p>
                <ul>
                    <li> A larger group of memory than the stack. </li>
                    <li> In the heap, the OS basically finds spot in the heap to fit the data, which can be a challenge for large data structures. </li>
                    <li> This can lead to gaps of unused memory, memory fragmentation. </li>
                    <li> It takes longer to allocate and deallocate memory in the heap because of this. </li>
                    <li> Data referenced by pointers is typically stored in the heap, pointers are usually on the stack. </li>
                    <li> Heap is for data that needs to persist beyond the lifetime of a function (pointers). </li>
                    <li> Heap is bigger than stack. </li>
                </ul>
                <div class = "links">
                    <a href = "https://www.geeksforgeeks.org/stack-vs-heap-memory-allocation/" target = "_blank"> Stack vs Heap Memory Allocation (GeeksforGeeks) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Cache, memory, cache line </b> </p>
            <div class = "subsectionContent"> 
                <p> When executing a function, the assembly instructions and data for that function are usually stored sequentially. In order to speed up execution, the OS will prefetch a section of code instructions and data surrounding the current instruction location and store it in the cache, which is a very small, very fast bit of memory that is close to the CPU. While executing the function, the CPU will check the cache to see if the next instruction/data is in the cache. If it is, there is no need to go back to main memory to fetch the data. However, if it is not in the cache, this is a cache miss, and the data must be fetched from a lower cache level or main memory. The cache line is the amount of data that is read into the cache aat once. Since the cache relies on things being sequential, data structures that aren't contiguous can have many cache misses, stuff like graphs, trees, linked lists. Arrays have relatively fewer cache misses, since data is stored sequentially. There are multiple levels of caches, L1 is the fastest. </p>
                <div class = "links">

                    <a href = "https://medium.com/software-design/why-software-developers-should-care-about-cpu-caches-8da04355bb8a" target = "_blank"> Why software developers should care about CPU caches (EventHelix) </a>
                    <br/>
                    <a href = "https://rastergrid.com/blog/gpu-tech/2021/01/understanding-gpu-caches/" target = "_blank"> Understanding GPU caches (Rastergrid) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> GPU Architecture </b> </p>
            <div class = "subsectionContent"> 

                <p> Thread - single invocation of a shader </p>
                <p> simd group/warp - group of 32 threads. this size is fixed by the GPU. in a simd group, all threads are run in parallel in at once on a single gpu core. </p>
                <p> threadgroup/wavefront - group of threads. this</p>
                <p> Thread masking - gpus execute simd groups in parallel and in lock step. as an example, if there is an add instruction in a shader, the gpu will fetch the inputs to the add instruction all at once, and execute the add instruction all at once, and write the result at once. This works great for efficiency, but causes an issue for threads with if statements and loops (divergent threads). This is because some threads will execute different instructions. To solve this, the GPU will execute both branches of the if statement for each thread. The gpu will use thread masking to ignore the writes to the registers for the threads that are not supposed to be executing the instructions. This is why if statements should generally be avoided if possible. </p>
                <p> Command Buffer - Instructions for a GPU draw call are stored in a command buffer. Stuff like pipeline state, buffer bindings, rendering mode (triangles, points, lines). OpenGL/WebGL do not expose command buffers through their APIs, but they are first class citizens in Metal/Vulkan/other modern APIs. </p>
                <p> Command Queue - Command buffers are submitted to the command queue, which holds the command buffers for the draw calls. </p>
              
                <div class = "links">
                    <a href = "http://www.icl.utk.edu/~luszczek/teaching/courses/fall2016/cosc462/pdf/GPU_Fundamentals.pdf" target = "_blank"> GPU Fundamentals (Jeff Larkin) </a>
                    <br/>
                    <a href = "https://aschrein.github.io/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html" target = "_blank"> What's up with my branch on GPU? (Anton Schrein) </a>
                    <br/>
                    <a href = "https://developer.apple.com/library/archive/documentation/Miscellaneous/Conceptual/MetalProgrammingGuide/Cmd-Submiss/Cmd-Submiss.html" target = "_blank"> Command Organization and Execution Model (Apple) </a>
                </div>
            </div>


            <h2 class = "sectionHeader"> Rendering Techniques </h2>
            <p class = "subsectionHeader"> <b> PBR </b> </p>
            <div class = "subsectionContent"> 
                <p> Physically Based Rendering, a way to realistically compute the way light interacts with materials. PBR uses BRDFs to approximate the rendering equation, and is generally photorealistic. PBR models typically have a diffuse/albedo component, a specular/gloss component, a roughness, a metallness, and emmission components. Not all of the components correspond to exact photorealistic parameters, are are used for artists to be able to tune stuff. </p>
            </div>              
            <p> <b> Forward Rendering </b> </p>
            <p> <b> Deferred rendering </b> </p>
            <p> <b> Visibility buffer rendering </b> </p>
            <p> <b> Shadow mapping </b> </p>
            <p> <b> mipmapping, reasons for doing </b> </p>
            <p class = "subsectionHeader"> <b> Tone mapping </b> </p>
            <div class = "subsectionContent"> 
                <p> A way to approximate HDR content on an low dynamic range screen. </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Tone_mapping" target = "_blank"> Tone Mapping (Wikipedia) </a>
                </div>
            </div>
            <p> <b> bloom </b> </p>
            <p> <b> ray tracing </b> </p>

            <h2 class = "sectionHeader"> C++ stuff </h2>
            <p> <b> virtual function </b> </p>
            <p> <b> pointers </b> </p>
            <p> <b> pointer vs reference </b> </p>
            <p> <b> templated classes </b> </p>
            <p> <b> static </b> </p>
            <p> <b> padding </b> </p>
            <p> <b> mutex semaphore </b> </p>
            <p> <b> paging </b> </p>

            <h2 class = "sectionHeader"> Data Structures/Algorithms </h2>
            <p class = "subsectionHeader"> <b> DFS/BFS </b> </p>
            <div class = "subsectionContent">
                <p> Depth First Search and Breadth First Search. The DFS/BFS algorithms are pretty simple, and they come up occasionally. The iterative cases are very similar to each other. The iterative DFS is usually better than recursive, since large trees could cause the program to run out of stack memory. </p>
                <div class = "codeBlock">
                    <code> 
                        <pre>
 //The main difference between dfsIterative and bfsIterative is one
 //function uses pushFront while the other uses pushBack.
 void dfsIterative(TreeNode* root) {
     if (root == NULL) {
         return;
     }
     <b>stack s;
     s.push(root);</b>
 
     while (!s.empty()) {
         TreeNode* n = <b>s.pop();</b>
         process(n);
         for (TreeNode* child: n->children) {
             if (child != NULL) {
                 s.<b>push</b>(child);
             }
         }
     }
 }
 
 void bfsIterative(TreeNode* root) {
     if (root == NULL) {
         return;
     }     
     <b>queue q;
     q.enqueue(root);</b>
 
     while (!q.empty()) {
         TreeNode* n = <b>q.dequeue();</b>
         process(n);
         for (TreeNode* child: n->children) {
             if (child != NULL) {
                 q.<b>enqueue</b>(child);
             }
         }
     }
 }
 
 //DFS can also be done recursive
 void dfsRecursive(TreeNode* root) {
     if (root == NULL) {
         return;
     }
 
     process(root);
     for (TreeNode* child: root->children) {
         dfsRecursive(child);
     }
 }</pre> </code>
                </div>
            </div>
            <br/>

            <p class = "subsectionHeader"> <b> Reverse Linked List </b> </p>
            <div class = "subsectionContent">
                <p> Been asked this question twice, its pretty simple to do in linear time. </p>
                <div class = "codeBlock">
                    <code> 
                        <pre>
 ListNode* reverse(ListNode* head) {
     ListNode* currentNode = head;
     ListNode* nextNode = head->next;
     currentNode->next = NULL;
 
     while (nextNode != NULL) {
         ListNode* newNextNode = nextNode->next;
         nextNode->next = currentNode;
         currentNode = nextNode;
         nextNode = newNextNode;
     }
     
     //new head of the list
     return currentNode;
 }</pre>
                    </code>
                </div>
            </div>
            <br/>

            <p class = "subsectionHeader"> <b> Spacial Data Structures </b> </p>
            <div class = "subsectionContent">
                <p> Used to query spacial data in sub-linear time. Still takes linear time to build spacial data structures. </p>
                <p> k-d tree - partition data along alternating dimensions </p> 
                <p> Bounding Volume Hierarchy - Create bounding boxes around objects, then more bounding boxes around groups of objects </p> 
                <p> Binary Space Parition - Partition data using planes </p> 
                <p> Octree - tree where each node has 8 children </p> 
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/K-d_tree" target = "_blank"> k-d tree (Wikipedia) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Bounding_volume_hierarchy" target = "_blank"> BVH (Wikipedia) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Binary_space_partitioning" target = "_blank"> BSP (Wikipedia) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Octree" target = "_blank"> Octree (Wikipedia) </a>
                    <br/>
                </div>


            </div>


            <p class = "subsectionHeader"> <b> Linked List vs Arrays </b> </p>
            <div class = "subsectionContent">
                <p class = "noBottom"> Linked List </p>
                <ul> 
                    <li> A chain of nodes that contain pointers to the next and previous nodes in the list. </li>
                    <li> Very quick to add, remove, and insert elements into the list. </li>
                    <li> Generally takes linear time to find the nth element in the list. </li>
                    <li> Won't have the best cache performance, since list nodes aren't neccesarily next to each other in memory. </li>
                </ul>

                <p class = "noBottom"> Array </p>
                <ul> 
                    <li> Collection of elements in a continous group of memory. </li>
                    <li> Very quick to index into the array to the nth element. </li>
                    <li> Can't resize the array without creating a new array and copying data over. </li>
                    <li> Generally takes linear time to remove an element from an array. </li>
                    <li> Typically has good cache performance since data is contiguous. </li>
                </ul>
            </div>

            <h2 class = "sectionHeader"> Other stuff </h2>
            <p class = "subsectionHeader"> <b> Cloth Simulation </b> </p>
            <div class = "subsectionContent"> 
                <p> Common cloth simulation methods are mass/spring. Bunch of cloth vertices are connected by springs that keep the vertices in place. There are structural springs, which are for adjacent vertices in the face. Shear vertices are for non-adjacent vertices in a face. Flexion/bend vertices are 'two hops' away. </p>

                <div class = "links"> 
                    <a href = "https://www.cs.umd.edu/class/fall2019/cmsc828X/LEC/Wei_Cloth.pdf" target = "_blank"> Cloth Simulation (Zhen Wei) </a>
                    <br/>
                    <a href = "https://docs.blender.org/manual/en/latest/physics/cloth/introduction.html" target = "_blank"> Introduction to Cloth (Blender) </a>
                    <br/>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Subdivision Surfaces </b> </p>
            <div class = "subsectionContent"> 
                <p> Process of smoothing out a surface and adding more geometry. Most common technique is Catmull-Clark. Typically we use half-edge data structures to represent meshes that we want to subdivide. </p>
                <div class = "links">
                    <a href = "https://en.wikipedia.org/wiki/Subdivision_surface" target = "_blank"> Subdivision Surface (Wikipedia) </a>
                    <br/>                    
                    <a href = "https://en.wikipedia.org/wiki/Catmullâ€“Clark_subdivision_surface" target = "_blank"> Catmull-Clark (Wikipedia) </a>
                    <br/>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Fluid Simulation </b> </p>
            <div class = "subsectionContent"> 
                <p> Fluid simulation involves solving the Navier-Stokes equation, which model forces like gravity, pressure, viscosity, etc. Two main types of fluid: Eulerian and Lagrangian. Lagrangian is about tracking individual particles in the simulation, while Eulerian is about tracking the flow of particles through a specific location, rather than individual particles. Lagrangian is a particle based approach (mesh free), while Eulerian is a grid/mesh based approach.  </p>
                <div class = "links"> 
                    <a href = "https://www.cs.rpi.edu/~cutler/classes/advancedgraphics/S09/lectures/08_fluid_simulation.pdf" target = "_blank"> Navier-Stokes & Flow Simulation (Barb Culter) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field" target = "_blank"> Eulerian vs Lagangian (Wikipedia) </a>
                    <br/>
                    <a href = "https://en.wikipedia.org/wiki/Navierâ€“Stokes_equations" target = "_blank"> Navier-Stokes equations (Wikipedia) </a>
                </div>
            </div>

            <p class = "subsectionHeader"> <b> Integration methods </b> </p>
            <div class = "subsectionContent"> 
                <p> Explicit Euler, Implicit Euler, and Runge-Kutta (RK4) are common integration methods. Euler is typically unstable on forces that vary with time/distance/position. RK4 doesn't have as many issues, but it's more complicated. </p>
                <div class = "links"> 
                    <a href = "https://www.cs.umd.edu/class/fall2019/cmsc828X/LEC/Wei_Cloth.pdf" target = "_blank"> Cloth Simulation (Zhen Wei) </a>
                </div>
            </div>
            
            <p class = "subsectionHeader"> <b> Apple Silicon </b> </p>
            <div class = "subsectionContent">
                <p> If you want to work for Apple (or are just interested), you'll want to be familiar with Apple Silicon. </p>
                <div class = "links">
                    <a href = "https://developer.apple.com/videos/play/tech-talks/10859" target = "_blank"> Tailor your Metal apps for Apple M1 (Apple) </a>
                    <br/>
                    <a href = "https://developer.apple.com/videos/play/wwdc2020/10631/" target = "_blank"> Bring your Metal app to Apple silicon Macs (Apple) </a>
                    <br/>
                    <a href = "https://developer.apple.com/videos/play/wwdc2020/10632/" target = "_blank"> Optimize Metal Performance for Apple silicon Macs (Apple) </a>
                    <br/>
                    <a href = "https://developer.apple.com/videos/play/tech-talks/10858/" target = "_blank"> Discover Metal enhancements for A14 Bionic (Apple) </a>
                    <br/>
                    <a href = "https://developer.apple.com/videos/play/wwdc2019/601/" target = "_blank"> Modern Rendering with Metal (Apple) </a>
                </div>

            </div>

            <p class = "subsectionHeader"> <b> Node based graphs </b> </p>
            <div class = "subsectionContent"> 
                <p> Lots of rendering/vfx stuff uses node graphs to represent shaders/render passes/materials/etc. </p>
                <div class = "links">
                    <a href = "https://unity.com/shader-graph" target = "_blank"> Unity Shader Graph </a>
                    <br/>
                    <a href = "https://unity.com/visual-effect-graph" target = "_blank"> Unity Visual Effect Graph </a>
                    <br/>
                    <a href = "https://levelup.gitconnected.com/organizing-gpu-work-with-directed-acyclic-graphs-f3fd5f2c2af3" target = "_blank"> Organizing GPU Work with Directed Acyclic Graphs </a>
                    <br/>
                    <a href = "https://apoorvaj.io/render-graphs-1/" target = "_blank"> Render graphs </a>
                    <br/>
                    <a href = "http://simonstechblog.blogspot.com/2019/07/render-graph.html" target = "_blank"> Render Graph </a>
                </div>
            </div>

<!--

            <h2 class = "resumeHeading"> Powers of 2 </h2>
            <div class = "heading">
                <p>
                    Yes, really. I've been directly asked about them in at least 2<sup>1</sup> interviews.
                </p>
                <p>
                    I just know that 2<sup>4</sup> = 16, 2<sup>8</sup> = 256, and that I can multiply or divide by 2 to get whatever specific power of 2 I get asked to compute.
                </p>
            </div>
            
            <h2 class = "resumeHeading"> Hexadecimal </h2>
            <div class = "heading">
                <p>
                    I've been asked about this a few times too. Hex is a base-16 number system. Digits 0-9 are the same as decimal, but 10 = A, 11 = B, 12 = C, 13 = D, 14 = E, 15 = F. Four binary digits corresponds to one hex digit.
                </p>
            </div>

            <h2 class = "resumeHeading"> Two's compliment </h2>
            <div class = "heading">
                <p>
                </p>
            </div>

            <h2 class = "resumeHeading"> The Rendering Equation </h2>
            <div class = "heading">
                <p> From <a style = "text-decoration:none;color:var(--siteColor);" href = "https://en.wikipedia.org/wiki/Rendering_equation" target = "_blank">Wikipedia</a>, the rendering equation is: </p>
                <img src = "https://wikimedia.org/api/rest_v1/media/math/render/svg/3955fb75fee8d1ace1e117f728dd33f919262b36" style = "width: 80%;"/>

                <p>
                    <i>For each input direction wi, calculate the light absorbed by the surface along wi (Li * wi&#183;n), then multiply that value by the amount of the absorbed light that exits the surface in the direction of wo (fr). Then, if the surface itself emits light, calculate the amount of emitted light that leaves the surface along wo and add it to the previous sum (Le). This is equal to the total amount of light that leaves the surface along wo (Lo).</i>
                </p>

                <p>
                    Let's break it down in more detail, starting with the integral. This integral is a hemisphere integral, which means we are integrating over all possible input directions in the hemisphere above the surface. Next, fr(wi, wo), the BRDF of the surface. The BRDF is the ratio of light reflected along wo (radiance) divided by the light absorbed along wi (irradiance). Then, the term Li wi&#183;n. Typically, this is broken down into two terms, but I like to think of it as the irradiance term. This is because it allows the BRDF, which is radiance/irradiance, to 'cancel out' the irradiance term and leave us with radiance left in the integral.
                </p>



                <p>
                    To understand why the irradiance term has a dot product in it, we need to look at the definition of irradiance. Irradiance is flux per unit area. We can think of the flux portion of the irradiance term as the incoming radiance Li. This means the dot product is the 'per unit area' portion of the irradiance. But how? The way I think about it is by using a flashlight. If you shine a flashlight directly down on a surface, it makes a circle of light on the surface. However, if you shine the flashlight on the surface at an angle, the circle of light turns into an ellipse, which has a larger area than the circle. If the radiance from the flashlight remains constant, and the surface area increases, the irradiance will decrease, since irradiance is flux per unit area. It turns out we can model this behavior by using the dot product term.
                </p>

                <p>
                    A few more things about the rendering equation. In most cases, there is no closed-form solution to the integral. The rendering equation must be solved analytically. Luckily, we have computers to do that for us! The basic rendering equation does not capture some rendering effects like subsurface scattering and transmission. However, the rendering equation can be modified to accomodate these effects.
                </p>
            </div>

            <h2 class = "resumeHeading"> BXDFs - BRDF, BSSDF, and more </h2>
            <div class = "heading">
                <p>
                    BXDF stands for Bidirectional X Distribution Function - where the X is either Reflectance, Subsurface Scattering, Transmission, or other words, depending on the context. Generally, a BXDF is a function that returns the ratio of radiance to irradiance for specified input and output light directions. The simplest of the BXDF is the Bidirectional Reflectance Distribution Function, or BRDF. The BRDF will take in a direction towards the light source, wi, and the direction out of the surface/towards the camera, wr. From <a style = "text-decoration:none;color:var(--siteColor);" href = "https://en.wikipedia.org/wiki/Bidirectional_reflectance_distribution_function" target = "_blank">Wikipedia</a>:
                </p>

                <img src = "https://upload.wikimedia.org/wikipedia/commons/e/ed/BRDF_Diagram.svg" style = "width: 30%;"/>

                <p>

                </p>

                <p>
                </p>

                <p>
                </p>
            </div>

            <h2 class = "resumeHeading"> Deferred Rendering </h2>
            <div class = "heading">
                <p>
                    Deferred rendering is a screen-space rendering algorithm with two rendering passes instead of one. Normally, lighting calculations are performed in the fragment shader. However, in deferred rendering, the fragment shader instead writes the fragment inputs like diffuse color, specular color, depth, and normals to 4 separate textures. These textures are called the G-buffer. After all fragments have been processed, a second rendering pass combines the 4 textures together, along with the lighting, to create the final image.
                </p>
                <p>
                    Why deferred rendering? In large rendering engines, there is a concept of a draw call. A draw call contains mesh data, textures, and other data to render the mesh. A draw call typically doesn't contain all of the geometry in a scene, so multiple draw calls are needed to fully render a scene. In a game, this might mean that the mountains in the background are one draw call, the trees are some more draw calls, each enemy is another draw call, and the player is another draw call. These draw calls may be done sequentially or in parallel. If we compute expensive lighting calculations in the fragment shader for the mountain draw call, it's likely that a majority of the computed pixels will be occluded by other geometry, which means those computations are wasted.
                </p>
                <p>
                    Now, if you are knowledgable of the graphics pipeline, you may know that some pipelines include early depth testing that occurs before the fragment shader. While this is true, not all graphics pipelines support this, and some only perform depth testing after the fragment shader. Additionally, going back to the example from earlier, if the first draw call renders the mountains and all subsequent draw calls render in front of the mountains, we would still be performing lighting computations on the mountains that wouldn't be removed via early depth testing because the mountains were in a separate draw call from the other geometry. This is why we use deferred rendering!
                </p>
                <p>
                    There are some disadvantages to deferred rendering, however. It doesn't handle transparent geometry, so you'd need to fall back to standard forward rendering to handle transparent surfaces. It also uses more memory for the G-buffer, which may be an issue on memory-constrained GPUs.
                </p>
            </div>


            <h2 class = "resumeHeading"> </h2>
            <div class = "heading">
                <p>
                </p>
            </div>
        -->
        </div>
        
        <!--<script type = "text/javascript" src = "scripts/header.js"> </script>-->
        <div class = "footer">
            <p> :) </p>
            <a href = "index.html"> <img src = "pictures/logo-white.png"> </img> </a>
            <div class = "linkBox">
                <a href = "../../index.html"> Home </a>
            </div>
        </div>
        <script type = "text/javascript" src = "../../scripts/footer.js"> </script>
        
        
    </body>
</html>


<!--
 
 -->
