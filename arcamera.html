<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="styles.css"> </link>
        <title> AR Camera Layout Tool </title>
        <meta name = "viewport" content = "width=1000"> </meta>
    </head>
    
    <body>
        <div class = "content">
            <div class = "bar" id = "sidebar">
                <a href = "index.html"> Home </a>
                <noscript>
                    <p> Please enable Javascript for side bar to work. </p>
                </noscript>
            </div>
            
            <h1> AR Camera Layout Tool </h1>
            <p>
                This tool allows layout artists to create camera shots using augmented reality. A scene is modeled and animated in Maya, then imported into an app which displays the scene in AR. Next, the user moves around the AR scene while the app records the position and rotation of the AR camera. Finally, the camera position data is exported from the app and imported into a Maya plugin, which generates keyframes on a Maya camera.
            </p>

            <div class = "links">
                <a href = "https://github.com/kellyme213/ResearchProject" target = "_blank"> Source Code </a>
            </div>


            <h2 class = "resumeHeading"> The App </h2>
            <div class = "heading">
                <p>
                    The app runs on iOS and utilizes RealityKit and ARKit. To add a scene to the app, a user places a <a style = "text-decoration:none;color:var(--siteColor);" href = "https://graphics.pixar.com/usd/docs/Usdz-File-Format-Specification.html">USDZ<a/> file in the Files app. This USDZ file is generated from an exported FBX file using Apple's <a style = "text-decoration:none;color:var(--siteColor);" href = "https://developer.apple.com/download/more/?=USDPython">usdzconvert</a> command line tool.
                </p>
            </div>

            <ul class = "imagelist">
                <img src = "pictures/arcamera/files1.png" style = "width: 40%"/>
                <img src = "pictures/arcamera/files2.png" style = "width: 40%"/>
            </ul>

            <p>
                After this, the USDZ files will appear in the AR app. Once a scene is selected, users can specify a project name that is part of the output file name. This helps organize the output files.
            </p>

            <ul class = "imagelist">
                <img src = "pictures/arcamera/main1.png" style = "width: 40%"/>
                <img src = "pictures/arcamera/main2.png" style = "width: 40%"/>
            </ul>

            <p>
                Once the app is displaying the scene in AR, users can adjust the scale and position of the scene if nessesary. The file name of the outputted data is displayed in the bottom left of the screen. The scene below is a screenshot of 'test.usdz' with project name 'test' and shot '02'. Shot numbers are automatically generated by the app starting at 1.
            </p>

            <ul class = "imagelist">
                <img src = "pictures/arcamera/app.png" style = "width: 90%"/>
            </ul>

            <p>
                When the user presses start, the scene will begin animating and the app will start to record the camera's position and rotation. Once the stop button is pressed, the app starts recording, saves the data to the specified file name, and returns to the selection screen. Data is saved to a .camout file, which contains the data from the AR camera recording. It is accessible in the Files app.
            </p>

            <ul class = "imagelist">
                <img src = "pictures/arcamera/files5.png" style = "width: 90%"/>
            </ul>

            <iframe src = "https://www.youtube.com/embed/YDPxdqxER3s"> </iframe>
            <br/>


            <h2 class = "resumeHeading"> The Plugin </h2>
            <div class = "heading">
                <p>
                    The Maya plugin is written in Python and utilizes PyMEL and PySide. After camera data has been generated by the app, it is copied from the Files app to a computer running Maya. 
                </p>

                <p>
                    From the plugin's GUI, a .camout file is selected and imported. Next, users select a Maya camera to bake the AR camera data on to. Then, keyframes are generated based on the AR camera data.
                </p>
            </div>

            <iframe src = "https://www.youtube.com/embed/Rj187YWwCaw"> </iframe>
            <br/>


            <h2 class = "resumeHeading"> Discussion and Limitations </h2>
            <div class = "heading">
                <p>
                    The camera data recorded by the app closely matches the generated keyframes in Maya. However, due to differences in aspect ratio and focal length of the AR and Maya cameras, the framing of the scene between the two cameras will differ. This is a limitation that is difficult to fix, since AR cameras have a fixed focal length, while Maya cameras can have multiple focal lengths. Additionally, AR camera position tracking is very jittery, which is not ideal for animation. Camera position data can be filtered to reduce jitter, or jittery keyframes can be manually adjusted.
                </p>
            </div>
            <iframe src = "https://www.youtube.com/embed/Y5KEHYH7Rf4"> </iframe>
            <br/>

            
            <div class = "links">
                <a href = "https://github.com/kellyme213/ResearchProject" target = "_blank"> Source Code </a>
            </div>

        </div>
        
        <script type = "text/javascript" src = "scripts/bar.js"> </script>
        <script>
            document.getElementById("arCameraBar").className = "selectedbar";
        </script>
        
        <div class = "footer">
            <p> Created By Michael Kelly </p>
            <a href = "index.html"> <img src = "pictures/logo-white.png"> </img> </a>
            <div class = "linkBox">
                <a href = "index.html"> Home </a>
            </div>
        </div>
        <script type = "text/javascript" src = "scripts/footer.js"> </script>
        
    </body>
</html>

<!--
 
 -->
